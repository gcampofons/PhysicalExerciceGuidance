# ðŸ‹ AI Exercise Trainer

A real-time exercise guidance application that uses your webcam and AI pose estimation to count repetitions and provide live form feedback â€” no gym equipment or wearables required.

![Python](https://img.shields.io/badge/Python-3.11%2B-blue)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10%2B-orange)
![PyQt6](https://img.shields.io/badge/PyQt6-6.6%2B-green)
![YOLOv8](https://img.shields.io/badge/YOLOv8-ultralytics-purple)

---

## Features

- **Dual pose-estimation backends** â€” switch live between âš¡ MediaPipe (33 keypoints) and ðŸŽ¯ YOLOv8-Pose (17 COCO keypoints) with a single click; no restart needed
- **Backend label on frame** â€” the active backend (`[MEDIAPIPE]` or `[YOLO]`) is stamped directly onto the camera feed so there is never any doubt which engine is running
- **Automatic rep counting** â€” UP/DOWN state machine triggered by joint angle thresholds
- **Live form feedback** â€” colour-coded coaching tips per exercise (green = good, amber = needs improvement, red = warning)
- **Visibility guard** â€” rep counting is frozen when joints move out of frame to prevent phantom reps
- **33 exercises out of the box** â€” covering squats, curls, presses, rows, hinges, lunges, plyometrics and more (full list below)
- **Professional dark UI** â€” built with PyQt6; camera feed is a component inside the layout, not a raw OpenCV window
- **JSON-driven exercise registry** â€” add or edit exercises in `core/exercises_data.json` with no Python required

---

## Screenshots

| Menu | Exercise in progress |
|---|---|
| Exercise list with tips | Skeleton overlay + angle gauge + rep counter |

---

## Requirements

- Python 3.11 or later
- Webcam
- Windows (tested), macOS / Linux should work with minor `CAP_DSHOW` changes

---

## Installation

```bash
# 1. Clone the repo
git clone https://github.com/your-username/PhysicalExerciceGuidance.git
cd PhysicalExerciceGuidance

# 2. Create and activate a virtual environment
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # macOS / Linux

# 3. Install dependencies
pip install -r requirements.txt
```

> **MediaPipe** â€” the pose landmarker model (~5 MB) is downloaded automatically on first launch and cached at `assets/models/pose_landmarker_lite.task`.
>
> **YOLOv8** (optional) â€” `ultralytics` and a CPU-only PyTorch build are required. Install them once:
> ```bash
> pip install ultralytics
> pip install --force-reinstall torch torchvision --index-url https://download.pytorch.org/whl/cpu
> ```
> The YOLOv8n-pose weights (~6 MB) are downloaded automatically by `ultralytics` on first use and cached in `%APPDATA%\Ultralytics\` (Windows).

---

## Usage

```bash
python main.py
```

1. The app opens with a list of exercises in the left sidebar.
2. Click an exercise to select it â€” the sidebar shows a coaching tip.
3. Stand in front of your webcam so the relevant joints are visible.
4. Perform the movement â€” reps and form feedback update in real time.
5. Click **â†º Reset Reps** to restart the counter for a new set.
6. Use the **âš¡ MediaPipe** / **ðŸŽ¯ YOLOv8** buttons in the top bar to switch the pose-estimation engine live at any time.

---

## Project Structure

```
PhysicalExerciceGuidance/
â”‚
â”œâ”€â”€ main.py                        # Entry point â€” starts the Qt application
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ pose_landmarker_lite.task   # Auto-downloaded on first run
â”‚
â”œâ”€â”€ core/                          # Pure domain logic â€” no UI, no OpenCV
â”‚   â”œâ”€â”€ config.py                  # Paths, camera settings, thresholds
â”‚   â”œâ”€â”€ landmarks.py               # 33 landmark index constants + skeleton connections
â”‚   â”œâ”€â”€ exercises.py               # Exercise dataclass + JSON loader â†’ REGISTRY
â”‚   â”œâ”€â”€ exercises_data.json        # All 33 exercise definitions (edit here to add/modify)
â”‚   â””â”€â”€ geometry.py                # angle_between(), landmark_xy()
â”‚
â”œâ”€â”€ detection/                     # ML / computer vision layer
â”‚   â”œâ”€â”€ keypoint.py                # Keypoint(x, y, visibility) dataclass â€” shared by all backends
â”‚   â”œâ”€â”€ base_detector.py           # BaseDetector ABC â€” context-manager + abstract detect()
â”‚   â”œâ”€â”€ pose_detector.py           # MediaPipe backend (auto-downloads model, VIDEO mode)
â”‚   â”œâ”€â”€ yolo_detector.py           # YOLOv8-Pose backend (COCO-17 â†’ MP-33 slot mapping)
â”‚   â”œâ”€â”€ detector_factory.py        # create_detector("mediapipe" | "yolo") factory
â”‚   â””â”€â”€ rep_counter.py             # UP/DOWN state machine
â”‚
â”œâ”€â”€ camera/
â”‚   â””â”€â”€ camera_thread.py           # QThread â€” orchestrates capture, detection, signals
â”‚
â””â”€â”€ ui/
    â”œâ”€â”€ main_window.py             # MainWindow â€” layout + slots, zero business logic
    â””â”€â”€ widgets/
        â”œâ”€â”€ angle_gauge.py         # Custom circular arc gauge
        â”œâ”€â”€ exercise_button.py     # Checkable sidebar button
        â””â”€â”€ stat_card.py           # Metric display card
```

---

## Adding a New Exercise

Edit `core/exercises_data.json` and append a new entry â€” no Python required:

```json
{
  "id": 33,
  "name": "My Exercise",
  "joint": ["LEFT_HIP", "LEFT_KNEE", "LEFT_ANKLE"],
  "down_max": 100,
  "up_min": 160,
  "tip": "Keep your front knee behind your toes.",
  "feedback": [
    { "angle_min": 0,   "angle_max": 100, "message": "âœ“ Good depth!",   "color": "#22c55e" },
    { "angle_min": 100, "angle_max": 160, "message": "â†“ Go lower",       "color": "#f59e0b" },
    { "angle_min": 160, "angle_max": 180, "message": "â†‘ Stand up fully", "color": "#94a3b8" }
  ]
}
```

Joint names must match a constant in `core/landmarks.py` (e.g. `LEFT_HIP`, `RIGHT_ELBOW`). The button appears in the sidebar automatically.

---

## Exercise List

| # | Exercise | Category |
|---|----------|----------|
| 0 | Squat | Legs |
| 1 | Bicep Curl | Arms |
| 2 | Push-up | Push |
| 3 | Lateral Raise | Shoulders |
| 4 | Overhead Press | Shoulders |
| 5 | Tricep Extension | Arms |
| 6 | Front Raise | Shoulders |
| 7 | Lunge | Legs |
| 8 | Shoulder Tap | Core |
| 9 | Hammer Curl | Arms |
| 10 | Reverse Curl | Arms |
| 11 | Concentration Curl | Arms |
| 12 | Overhead Tricep Extension | Arms |
| 13 | Skull Crusher | Arms |
| 14 | Tricep Kickback | Arms |
| 15 | Incline Push-up | Push |
| 16 | Diamond Push-up | Push |
| 17 | Arnold Press | Shoulders |
| 18 | Upright Row | Shoulders |
| 19 | Romanian Deadlift | Hip Hinge |
| 20 | Good Morning | Hip Hinge |
| 21 | Hip Thrust | Glutes |
| 22 | Sumo Squat | Legs |
| 23 | Bulgarian Split Squat | Legs |
| 24 | Jump Squat | Plyometrics |
| 25 | Step Up | Legs |
| 26 | Mountain Climber | Cardio / Core |
| 27 | Glute Bridge | Glutes |
| 28 | Donkey Kick | Glutes |
| 29 | Bent Over Row | Pull |
| 30 | Pull-up | Pull |
| 31 | Lat Pulldown | Pull |
| 32 | Calf Raise | Legs |

---

## How It Works

```
Webcam frame
    â”‚
    â–¼
create_detector(backend)       â† factory returns MediaPipe or YOLOv8 instance
    â”‚                             (backend toggled live from the top bar)
    â–¼
BaseDetector.detect()          â† returns list[Keypoint] (33 slots, MP order)
    â”‚                             YOLO maps COCO-17 â†’ MP-33; missing slots = 0.0 vis
    â–¼
visibility check               â† all 3 joints must be > 0.6
    â”‚  pass
    â–¼
geometry.angle_between()       â† angle at the middle joint (Aâ€“Bâ€“C)
    â”‚  angle Â°
    â–¼
RepCounter.update()            â† UP/DOWN state machine
    â”‚  reps, state
    â–¼
cv2.putText  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º [MEDIAPIPE] or [YOLO] label stamped on frame
    â”‚
    â–¼
Qt signals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º MainWindow slots (frame, stats, feedback)
```

> **YOLOv8 keypoint coverage**: YOLO provides 17 COCO keypoints (nose, eyes, ears, shoulders, elbows, wrists, hips, knees, ankles). Exercises that require face, finger, or toe landmarks (e.g. Calf Raise â€” `LEFT_FOOT_INDEX`) will show the visibility warning in YOLO mode. All 32 gym exercises work with both backends.

---

## Configuration

All tuneable constants live in `core/config.py`:

| Constant | Default | Description |
|---|---|---|
| `CAMERA_INDEX` | `0` | Webcam device index |
| `CAMERA_WIDTH` | `640` | Capture width (px) |
| `CAMERA_HEIGHT` | `480` | Capture height (px) |
| `MIN_DETECTION_CONFIDENCE` | `0.55` | MediaPipe detection threshold |
| `MIN_TRACKING_CONFIDENCE` | `0.55` | MediaPipe tracking threshold |
| `MIN_LANDMARK_VISIBILITY` | `0.6` | Below this, angle/rep logic is skipped |
| `POSE_BACKEND` | `"mediapipe"` | Default backend at startup (`"mediapipe"` or `"yolo"`) |

---

## Dependencies

| Package | Purpose |
|---|---|
| `mediapipe` | MediaPipe Pose Landmarker backend (33 keypoints, VIDEO mode) |
| `ultralytics` | YOLOv8-Pose backend (17 COCO keypoints, auto-downloads weights) |
| `torch` / `torchvision` | PyTorch CPU runtime required by ultralytics |
| `opencv-python` | Webcam capture + frame drawing |
| `numpy` | Vector math for angle calculation |
| `PyQt6` | Desktop UI framework |

---

## License

MIT
